{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Crack_train_on_cowi_data.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sayakgis/Air_Quality/blob/master/Crack_train_on_cowi_data_v0.1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "X3bXn5Wu47DS",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Training ResNET34 on COWI DDG images\n"
      ]
    },
    {
      "metadata": {
        "id": "KlPDjkSssoVL",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#GPU availability\n",
        "!nvidia-smi"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "KgojnxhiqHM-",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Import basic libraries\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os,shutil\n",
        "\n",
        "# Fastai reloads\n",
        "%reload_ext autoreload\n",
        "%autoreload 2\n",
        "%matplotlib inline\n",
        "\n",
        "#Impost fastai\n",
        "from fastai.vision import *\n",
        "from fastai.metrics import error_rate,accuracy\n",
        "from fastai.callbacks import *\n",
        "from fastai.imports import *\n",
        "\n",
        "from pathlib import Path"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "DesA_g9E8a4q",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "np.random.seed(42)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "On3oCFTrs6IZ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#download the data\n",
        "!wget --header=\"Host: storage.googleapis.com\" --header=\"User-Agent: Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/73.0.3683.103 Safari/537.36\" --header=\"Accept: text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3\" --header=\"Accept-Language: en-GB,en-US;q=0.9,en;q=0.8\" --header=\"Referer: https://www.kaggle.com/\" \"https://storage.googleapis.com/kaggle-datasets/180565/406017/data.zip?GoogleAccessId=web-data@kaggle-161607.iam.gserviceaccount.com&Expires=1557028882&Signature=ZQbUSiI7G9LK%2BKWd5%2BmoRJHiemRapKk%2F12pVxCI4M%2FV7ngTarjtlbHds5j64YvBmrmXwKznyIym7mzMcFMYX0LzK9VEqesP%2FmNC2vja5oFhHzc5KRLRzzunCEJFZZ9EEtboEB9VtP6tN1VSMc7ZldGrfd4iL0u6SlttLo4n0yn9Pcfsb2htPK%2B0wV%2By8MvZ3T3RSEATkBzoEAbGa6qcq8r8opWtae08ePwlnUwViGixu92pnRuTnPd5M4jAczpE4utI%2BVWSszqlrZ6KseVXAp9l1Avo3%2BYXr8ajbrte2kgZVMW9y1SBgAWmaa9Vh8MYAQr1%2FWKizi%2Ft3gpm3YbvOHQ%3D%3D\" -O \"data.zip\" -c"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Auyh4zma5Htz",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!zipinfo -1 data.zip"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "8ncYCqY-6OwD",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#unzip the folder\n",
        "!unzip data.zip"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "leB8h-it69jb",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!ls data/Crack_Detection"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "STbiaqbc8B7A",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#set path and size\n",
        "PATH=\"data/Crack_Detection/\"\n",
        "os.listdir(PATH)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ThSJRugz8WdE",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Create validation dataset\n",
        "#np.random.seed(12)\n",
        "pos=os.listdir(f'{PATH}Positive')\n",
        "neg=os.listdir(f'{PATH}Negative')\n",
        "\n",
        "#take 20%: 4000*2 in validation dataset\n",
        "val_pos=list(np.random.choice(pos,int(len(pos)/5),replace=False))\n",
        "val_neg=list(np.random.choice(neg,int(len(neg)/5),replace=False))\n",
        "\n",
        "#Create test dataset, take 3000*2 examples from validation datatset\n",
        "test_pos=list(np.random.choice(val_pos,int(len(val_pos)/2),replace=False))\n",
        "test_neg=list(np.random.choice(val_neg,int(len(val_neg)/2),replace=False))\n",
        "\n",
        "print('First 5 files of positive examples:',pos[:5])\n",
        "print('First 5 examples of validation set of positive examples:',val_pos[:5])\n",
        "#val_neg[:5]\n",
        "print('Total number of images in positive example:',len(pos))\n",
        "print('Total number of images in negative example:',len(neg))\n",
        "\n",
        "print('Total number of images in TEST negative example:',len(test_neg))\n",
        "print('Total number of images in TEST positive example:',len(test_pos))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Fiz0z6nG97Wd",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# remove\n",
        "for i in val_pos:\n",
        "  pos.remove(i)\n",
        "  \n",
        "for i in val_neg:\n",
        "  neg.remove(i)\n",
        "  \n",
        "for i in test_pos:\n",
        "  val_pos.remove(i)\n",
        "\n",
        "for i in test_neg:\n",
        "  val_neg.remove(i)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Vt79EPjzCjO1",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "print('Total number of independent training examples:',len(pos)+len(neg))\n",
        "print('Number of validation examples:',len(val_pos)+len(val_neg))\n",
        "print('Number of test examples:',len(test_pos)+len(test_neg))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "3W4krUlVEbQs",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#create folder structute for fastai\n",
        "os.makedirs(PATH+'train',exist_ok=True)\n",
        "os.makedirs(PATH+'valid',exist_ok=True)\n",
        "os.makedirs(PATH+'test',exist_ok=True)\n",
        "os.makedirs(PATH+'train/Positive',exist_ok=True)\n",
        "os.makedirs(PATH+'train/Negative',exist_ok=True)\n",
        "os.makedirs(PATH+'valid/Positive',exist_ok=True)\n",
        "os.makedirs(PATH+'valid/Negative',exist_ok=True)\n",
        "#os.makedirs(PATH+'test/Positive',exist_ok=True)\n",
        "#os.makedirs(PATH+'test/Negative',exist_ok=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "oBfYPZPLDZPY",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Move the positive examples to test folder\n",
        "path = f'{PATH}Positive/'\n",
        "moveto = f'{PATH}test/'\n",
        "files = test_pos\n",
        "#files.sort()\n",
        "for f in files:\n",
        "    src = path+f\n",
        "    dst = moveto+'p'+f\n",
        "   # print(f)\n",
        "    shutil.move(src,dst)\n",
        "    \n",
        "# Move the negative examples to test folder\n",
        "path = f'{PATH}Negative/'\n",
        "moveto = f'{PATH}test/'\n",
        "files = test_neg\n",
        "#files.sort()\n",
        "for f in files:\n",
        "    src = path+f\n",
        "    dst = moveto+'n'+f   #added n just to keep all files in same folder as the filename of rpostive and egatives are same\n",
        "    #print(f)\n",
        "    shutil.move(src,dst)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "F_f-gvbEEAJ9",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Move the positive examples to validation folder\n",
        "path = f'{PATH}Positive/'\n",
        "moveto = f'{PATH}valid/Positive/'\n",
        "files = val_pos\n",
        "#files.sort()\n",
        "for f in files:\n",
        "    src = path+f\n",
        "    dst = moveto+f\n",
        "   # print(f)\n",
        "    shutil.move(src,dst)\n",
        "    \n",
        "# Move the negative examples to validation folder\n",
        "path = f'{PATH}Negative/'\n",
        "moveto = f'{PATH}valid/Negative/'\n",
        "files = val_neg\n",
        "#files.sort()\n",
        "for f in files:\n",
        "    src = path+f\n",
        "    dst = moveto+f\n",
        "    #print(f)\n",
        "    shutil.move(src,dst)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "wCuM-E52sLK2",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#move remaining positive files to train folder\n",
        "path = f'{PATH}Positive/'\n",
        "moveto = f'{PATH}train/Positive/'\n",
        "files = os.listdir(path)\n",
        "#files.sort()\n",
        "for f in files:\n",
        "    src = path+f\n",
        "    dst = moveto+f\n",
        "   # print(f)\n",
        "    shutil.move(src,dst)\n",
        "    \n",
        "#move remaining negative files to train folder\n",
        "path = f'{PATH}Negative/'\n",
        "moveto = f'{PATH}train/Negative/'\n",
        "files = os.listdir(path)\n",
        "#files.sort()\n",
        "for f in files:\n",
        "    src = path+f\n",
        "    dst = moveto+f\n",
        "   # print(f)\n",
        "    shutil.move(src,dst)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "jXj6yqBoEeQb",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!ls data/Crack_Detection/Negative/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "1ecv4_4GENJA",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Resize train\n",
        "path =Path('data/Crack_Detection/')\n",
        "path_hr = path/'train'\n",
        "path_lr = path/'small-227'\n",
        "path_mr = path/'small-299'\n",
        "path_mhr=path/'small-350'\n",
        "\n",
        "il = ImageList.from_folder(path_hr)\n",
        "\n",
        "def resize_one(fn, i, path, size):\n",
        "    dest = path/fn.relative_to(path_hr)\n",
        "    dest.parent.mkdir(parents=True, exist_ok=True)\n",
        "    img = PIL.Image.open(fn)\n",
        "    targ_sz = resize_to(img, size, use_min=True)\n",
        "    img = img.resize(targ_sz, resample=PIL.Image.BILINEAR).convert('RGB')\n",
        "    img.save(dest, quality=75)\n",
        "\n",
        "# create smaller image sets the first time this nb is run\n",
        "sets = [(path_lr, 227), (path_mr, 299), (path_mhr, 350)]\n",
        "for p,size in sets:\n",
        "    if not p.exists(): \n",
        "        print(f\"resizing to {size} into {p}\")\n",
        "        parallel(partial(resize_one, path=p, size=size), il.items)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Dm1FOthIKeLq",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Resize test\n",
        "path =Path('data/Crack_Detection/')\n",
        "path_hr = path/'test'\n",
        "path_lr = path/'test-small-227'\n",
        "path_mr = path/'test-small-299'\n",
        "path_mhr=path/'test-small-350'\n",
        "\n",
        "il = ImageList.from_folder(path_hr)\n",
        "\n",
        "def resize_one(fn, i, path, size):\n",
        "    dest = path/fn.relative_to(path_hr)\n",
        "    dest.parent.mkdir(parents=True, exist_ok=True)\n",
        "    img = PIL.Image.open(fn)\n",
        "    targ_sz = resize_to(img, size, use_min=True)\n",
        "    img = img.resize(targ_sz, resample=PIL.Image.BILINEAR).convert('RGB')\n",
        "    img.save(dest, quality=75)\n",
        "\n",
        "# create smaller image sets the first time this nb is run\n",
        "sets = [(path_lr, 227), (path_mr, 299), (path_mhr, 350)]\n",
        "for p,size in sets:\n",
        "    if not p.exists(): \n",
        "        print(f\"resizing to {size} into {p}\")\n",
        "        parallel(partial(resize_one, path=p, size=size), il.items)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "QhaZ0nI1uzhO",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Resize valid\n",
        "path =Path('data/Crack_Detection/')\n",
        "path_hr = path/'valid'\n",
        "path_lr = path/'valid-small-227'\n",
        "path_mr = path/'valid-small-299'\n",
        "path_mhr=path/'valid-small-350'\n",
        "\n",
        "il = ImageList.from_folder(path_hr)\n",
        "\n",
        "def resize_one(fn, i, path, size):\n",
        "    dest = path/fn.relative_to(path_hr)\n",
        "    dest.parent.mkdir(parents=True, exist_ok=True)\n",
        "    img = PIL.Image.open(fn)\n",
        "    targ_sz = resize_to(img, size, use_min=True)\n",
        "    img = img.resize(targ_sz, resample=PIL.Image.BILINEAR).convert('RGB')\n",
        "    img.save(dest, quality=75)\n",
        "\n",
        "# create smaller image sets the first time this nb is run\n",
        "sets = [(path_lr, 227), (path_mr, 299), (path_mhr, 350)]\n",
        "for p,size in sets:\n",
        "    if not p.exists(): \n",
        "        print(f\"resizing to {size} into {p}\")\n",
        "        parallel(partial(resize_one, path=p, size=size), il.items)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "jUFZQ-OcKqIM",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "len(os.listdir('data/Crack_Detection/test-small-227'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "3P2q7CcSUdfk",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "os.listdir(PATH)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "eYVVut82wHiP",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Create data loader with 227 size image**"
      ]
    },
    {
      "metadata": {
        "id": "qdBkgYs9EOJu",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "data = ImageDataBunch.from_folder(PATH,train='small-227',valid='valid-small-227',test='test-small-227',ds_tfms=get_transforms(), \n",
        "                                  size=227, bs=256).normalize(imagenet_stats)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "bPGzga7fK6Xm",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "data.show_batch(3,figsize=(15,12))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "YRtSkKDNwPoi",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Load the pretrained model of public dataset**"
      ]
    },
    {
      "metadata": {
        "id": "-DGd8INGLEyq",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "learn=load_learner(PATH)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "7Bskv0PDwWUO",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Check pretrained weights**"
      ]
    },
    {
      "metadata": {
        "id": "lIBTxgHNLvsU",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "learn.model.state_dict()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "E7nL5VQgwnIm",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Check architechture of the model**"
      ]
    },
    {
      "metadata": {
        "id": "NqfvBkXiwrIC",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "learn.model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Jfyi7jimwyQW",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "learn.model_dir"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "poATP1v5w3P4",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Attach data loaded of DDG images at 227 size to the model**"
      ]
    },
    {
      "metadata": {
        "id": "zU2FJMxULx0X",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "learn.data=data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "wrRTXvHdw_sO",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Check classes of the data**"
      ]
    },
    {
      "metadata": {
        "id": "jHGFDtwhO_yT",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "learn.data.classes"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "81ql1OldxGJa",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Finding the optimal learning rate**"
      ]
    },
    {
      "metadata": {
        "id": "62_TsBVMMaIG",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "learn.lr_find()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "zVy5S5o6x_Sq",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "learn.recorder.plot()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "LlqV6zGGyZF5",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Let us set **Learning rate to 1e-1**"
      ]
    },
    {
      "metadata": {
        "id": "oyin8ZCWzwXq",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Run 5 epochos and see **"
      ]
    },
    {
      "metadata": {
        "id": "IuHauB9BMiFJ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "lr=1e-1\n",
        "learn.fit_one_cycle(5,slice(lr))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "iiTCiJxxO1UW",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "learn.recorder.plot_losses()\n",
        "plt.title('Plot of Loss function')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "3FQy41cp1rVH",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Seeing the loss in validation set compared to training set it looks that the model is underfitting"
      ]
    },
    {
      "metadata": {
        "id": "PWI47FsA0sG7",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Plot accuracy metric and error with learning rate**"
      ]
    },
    {
      "metadata": {
        "id": "AcKk9ZLx0DtL",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "learn.recorder.plot_metrics()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "o96PZAU509wb",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "It is seen that the model is improving even at epoch 5 so let us train for 2 more epochs and see"
      ]
    },
    {
      "metadata": {
        "id": "l6YaiPyF0Sep",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "learn.fit_one_cycle(2,slice(lr))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ov-QVOuo16fs",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Now the validation loss and training loss is very close"
      ]
    },
    {
      "metadata": {
        "id": "ITQ7L6gG2GQg",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "learn.recorder.plot_lr()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "mGOCyxEa2c8l",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Let us see the results on validation set**"
      ]
    },
    {
      "metadata": {
        "id": "rA7IH1sP1RR6",
        "colab_type": "code",
        "colab": {},
        "cellView": "both"
      },
      "cell_type": "code",
      "source": [
        "#@title\n",
        "learn.show_results(3)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "wDOLri8R25M7",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**See top most misclassifications**"
      ]
    },
    {
      "metadata": {
        "id": "1GwEhbMM2nv6",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "interp = ClassificationInterpretation.from_learner(learn)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "CMCd9Wyq31qR",
        "colab_type": "code",
        "colab": {},
        "cellView": "both"
      },
      "cell_type": "code",
      "source": [
        "#@title\n",
        "interp.plot_top_losses(25, figsize=(25,18),heatmap=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "sLO98Zcn3Awp",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "interp.plot_top_losses(25, figsize=(25,18),heatmap=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "3uVLjoDG3K-J",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "interp.plot_confusion_matrix(title='Confusion matrix on Validation dataset-227 size')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-STEDuvC8ihd",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "interp.most_confused()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "98N2DO-q79Vc",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#save the model\n",
        "learn.save('stage-1-model-ddgimg')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "o8oFg6Kk9F-P",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#export the model for inference\n",
        "learn.export('export-ddg.pkl')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "pECQNE109Ko5",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#save the weights and bias\n",
        "torch.save(learn.model.state_dict(),'data/Crack_Detection/models/stage-1-wts-resnet34-ddgimg.pth')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "hw_0Xr_H9Lsg",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!ls data/Crack_Detection/models/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "acRJcLYi9tcM",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Check prediction on Test dataset**"
      ]
    },
    {
      "metadata": {
        "id": "cPd5tkk19w56",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "len(learn.data.test_ds)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ixDN-Ljl93cw",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#turn the model in evaluation mode\n",
        "learn.model.eval()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "9LcnCBZV99uZ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#take random images from test dataset\n",
        "\n",
        "plt.figure(figsize=(18,12))\n",
        "plt.subplots_adjust(hspace=0.3,wspace=0.2)\n",
        "\n",
        "n=np.random.randint(0,len(learn.data.test_ds),9)\n",
        "\n",
        "for i,j in enumerate(n):\n",
        "  img=data.test_ds[j][0]\n",
        "  plt.subplot(3,3,i+1)\n",
        "  plt.imshow(np.rollaxis(img.data.numpy(),0,3))\n",
        "  pred,_,y=learn.predict(img)\n",
        "  if ((Path(learn.data.test_ds.x.items[j]).name[0])=='n'):\n",
        "         actual='Actual: Negative'\n",
        "  else:\n",
        "         actual='Actual: Positive'\n",
        "  plt.title(actual\n",
        "      +'\\nPrediction: '+str(pred)+'-'+str(np.round(y.numpy().max()*100,2))+'%')\n",
        "  plt.axis('Off')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "4nHwCqOF-Zjd",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "test_preds,y,test_loss=learn.get_preds(ds_type=DatasetType.Test,with_loss=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "MGay06glAzni",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "test_img_names = [Path(i).name for i in learn.data.test_ds.x.items]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "3OzY5CkPBP3J",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "len(test_img_names)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "2TRiKJqfBV9g",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "test_probs_df = pd.DataFrame(test_preds.numpy(), columns=learn.data.train_ds.classes)\n",
        "test_probs_df['image_name'] = test_img_names\n",
        "test_probs_df.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "sieeBvJHBajg",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "test_probs_df['pred_label']= test_preds.numpy().argmax(1)\n",
        "test_probs_df.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ik3_0UB6Bc9D",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "test_probs_df['true_label']=test_probs_df.image_name.apply(lambda x: 1 if x[0]=='p' else 0)\n",
        "test_probs_df.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "i3CCXGZ0Bg98",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score,f1_score,confusion_matrix,classification_report\n",
        "import seaborn as sns\n",
        "\n",
        "conf=confusion_matrix(y_pred=test_probs_df.pred_label,y_true=test_probs_df.true_label)\n",
        "\n",
        "sns.heatmap(conf,fmt='d',annot=True,cmap='gray_r',xticklabels=['Negative','Positive'],yticklabels=['Negative','Positive'],square=True,linecolor='black',linewidths=1)\n",
        "plt.title('Confusion Matrix on Test dataset of 227 images size')\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('Actual')\n",
        "\n",
        "print('Accuracy of prediction on test images:',np.round(100*accuracy_score(y_pred=test_probs_df.pred_label,y_true=test_probs_df.true_label),2),'%')\n",
        "print('\\nClassification report:\\n',classification_report(y_pred=test_probs_df.pred_label,y_true=test_probs_df.true_label))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "zjO56wDmIjwT",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**See the false cases**"
      ]
    },
    {
      "metadata": {
        "id": "OFLKHxEJDExv",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "false_case=test_probs_df[test_probs_df.pred_label!=test_probs_df.true_label]\n",
        "false_case.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "lYYmstetIqKW",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Visualise the wrong classifications**"
      ]
    },
    {
      "metadata": {
        "id": "Aywzb2EHIrC6",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(16,35))\n",
        "plt.subplots_adjust(hspace=0.2,wspace=0.1)\n",
        "\n",
        "for i in range(false_case.shape[0]):\n",
        "  plt.subplot(9,5,i+1)\n",
        "  #print(false_case.iloc[i][0])\n",
        "  plt.imshow(plt.imread(PATH+'test-small-227/'+false_case.iloc[i][2]))\n",
        "  plt.title('True label: '+str(false_case.iloc[i][4])+' \\n Predicted: '+str(false_case.iloc[i][3])+', Prob:'+str(np.round(np.max(false_case.iloc[i][:2])*100,2))+'%')\n",
        "  plt.axis('Off')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-BP-IzAhQmt2",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## GradCAM implimentation"
      ]
    },
    {
      "metadata": {
        "id": "OtoUytwdIbFe",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from fastai.callbacks.hooks import *\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "\n",
        "# hook into forward pass\n",
        "def hooked_backward(m, oneBatch, cat):\n",
        "    # we hook into the convolutional part = m[0] of the model\n",
        "    with hook_output(m[0]) as hook_a: \n",
        "        with hook_output(m[0], grad=True) as hook_g:\n",
        "            preds = m(oneBatch)\n",
        "            preds[0,int(cat)].backward()\n",
        "    return hook_a,hook_g\n",
        "\n",
        "# We can create a utility function for getting a validation image with an activation map\n",
        "def getHeatmap(val_index, learner, imgDataBunch):\n",
        "    \"\"\"Returns the validation set image and the activation map\"\"\"\n",
        "    # this gets the model\n",
        "    m = learner.model.eval()\n",
        "    tensorImg,cl = imgDataBunch.valid_ds[val_index]\n",
        "    # create a batch from the one image\n",
        "    oneBatch,_ = imgDataBunch.one_item(tensorImg)\n",
        "    oneBatch_im = vision.Image(imgDataBunch.denorm(oneBatch)[0])\n",
        "    # convert batch tensor image to grayscale image with opencv\n",
        "    cvIm = cv2.cvtColor(image2np(oneBatch_im.data), cv2.COLOR_RGB2GRAY)\n",
        "    # attach hooks\n",
        "    hook_a,hook_g = hooked_backward(m, oneBatch, cl)\n",
        "    # get convolutional activations and average from channels\n",
        "    acts = hook_a.stored[0].cpu()\n",
        "    #avg_acts = acts.mean(0)\n",
        "\n",
        "    # Grad-CAM\n",
        "    grad = hook_g.stored[0][0].cpu()\n",
        "    grad_chan = grad.mean(1).mean(1)\n",
        "    grad.shape,grad_chan.shape\n",
        "    mult = (acts*grad_chan[...,None,None]).mean(0)\n",
        "    return mult, cvIm\n",
        "\n",
        "# Then, modify our plotting func a bit\n",
        "def plot_heatmap_overview(interp:ClassificationInterpretation, learner, imgDataBunch, classes=data.classes):\n",
        "    # top losses will return all validation losses and indexes sorted by the largest first\n",
        "    tl_val,tl_idx = interp.top_losses()\n",
        "    #classes = interp.data.classes\n",
        "    fig, ax = plt.subplots(3,4, figsize=(16,12))\n",
        "    fig.suptitle('Grad-CAM\\nPredicted / Actual / Loss / Probability',fontsize=20)\n",
        "    # Random\n",
        "    for i in range(4):\n",
        "        random_index = random.randint(0,len(tl_idx))\n",
        "        idx = tl_idx[random_index]\n",
        "        act, im = getHeatmap(idx, learner, imgDataBunch)\n",
        "        H,W = im.shape\n",
        "        _,cl = interp.data.dl(DatasetType.Valid).dataset[idx]\n",
        "        cl = int(cl)\n",
        "        ax[0,i].imshow(im)\n",
        "        ax[0,i].imshow(im, cmap=plt.cm.gray)\n",
        "        ax[0,i].imshow(act, alpha=0.5, extent=(0,H,W,0),\n",
        "              interpolation='bilinear', cmap='inferno')\n",
        "        ax[0,i].set_xticks([])\n",
        "        ax[0,i].set_yticks([])\n",
        "        ax[0,i].set_title(f'{classes[interp.pred_class[idx]]} / {classes[cl]} / {interp.losses[idx]:.2f} / {interp.probs[idx][cl]:.2f}')\n",
        "    ax[0,0].set_ylabel('Random samples', fontsize=16, rotation=0, labelpad=80)\n",
        "    # Most incorrect or top losses\n",
        "    for i in range(4):\n",
        "        idx = tl_idx[i]\n",
        "        act, im = getHeatmap(idx, learner, imgDataBunch)\n",
        "        H,W = im.shape\n",
        "        _,cl = interp.data.dl(DatasetType.Valid).dataset[idx]\n",
        "        cl = int(cl)\n",
        "        ax[1,i].imshow(im)\n",
        "        ax[1,i].imshow(im, cmap=plt.cm.gray)\n",
        "        ax[1,i].imshow(act, alpha=0.5, extent=(0,H,W,0),\n",
        "              interpolation='bilinear', cmap='inferno')\n",
        "        ax[1,i].set_xticks([])\n",
        "        ax[1,i].set_yticks([])\n",
        "        ax[1,i].set_title(f'{classes[interp.pred_class[idx]]} / {classes[cl]} / {interp.losses[idx]:.2f} / {interp.probs[idx][cl]:.2f}')\n",
        "    ax[1,0].set_ylabel('Most incorrect\\nsamples', fontsize=16, rotation=0, labelpad=80)\n",
        "    # Most correct or least losses\n",
        "    for i in range(4):\n",
        "        idx = tl_idx[len(tl_idx) - i - 1]\n",
        "        act, im = getHeatmap(idx, learner, imgDataBunch)\n",
        "        H,W = im.shape\n",
        "        _,cl = interp.data.dl(DatasetType.Valid).dataset[idx]\n",
        "        cl = int(cl)\n",
        "        ax[2,i].imshow(im)\n",
        "        ax[2,i].imshow(im, cmap=plt.cm.gray)\n",
        "        ax[2,i].imshow(act, alpha=0.5, extent=(0,H,W,0),\n",
        "              interpolation='bilinear', cmap='inferno')\n",
        "        ax[2,i].set_xticks([])\n",
        "        ax[2,i].set_yticks([])\n",
        "        ax[2,i].set_title(f'{classes[interp.pred_class[idx]]} / {classes[cl]} / {interp.losses[idx]:.2f} / {interp.probs[idx][cl]:.2f}')\n",
        "    ax[2,0].set_ylabel('Most correct\\nsamples', fontsize=16, rotation=0, labelpad=80)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "H2pPBgsgP3oP",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "plot_heatmap_overview(interp,learn,data)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "8Mk3OLJCdqzn",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}